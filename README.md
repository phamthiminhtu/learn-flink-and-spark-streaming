# Learning Flink & Spark

A repo to explore different streaming mechanisms: Kafka, Flink, and Spark.

The main goal is to understand the core components of Flink and Spark in streaming pipelines and how each serves a different purpose.

Bonus point: got my elementary Java revised lol.

## How it works

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Producer   â”‚ â†’ Generates realistic clickstream events
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚    Kafka     â”‚ â†’ Message broker
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â”œâ”€â–º Flink
       â”‚
       â””â”€â–º Spark
             â”‚
             â–¼
       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
       â”‚  MinIO   â”‚ â†’ Data lake storage
       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## Learning points

1. Generate and publish simulated event data to Kafka âœ…
2. Build Spark micro batch jobs (30s latency): event -> kafka topic -> spark streaming -> S3 (MinIO) âœ…
```
# Set up
       docker compose up -d

# Simulate events:
       docker exec -it clickstream-producer python3 produce-test-events.py

# Submit Spark job
       ./spark/docker-run.sh submit <job name>
       
       # example
       ./spark/docker-run.sh submit jobs/sliding_window_exercise.py

# Check if data is streamed into MinIO at: http://localhost:9001/browser/lakehouse
```
3. Build Flink streaming jobs (real-time processing): event -> Kafka topic -> Flink -> Postgres âœ…
```
# Set up: 
       docker compose up -d

# Simulate events: 

       docker exec -it clickstream-producer python3 produce-test-events.py
# Submit Flink job
       cd flink
       ./docker-run.sh submit <job name>

# Check if data is streamed into Postgres db:

       docker exec -it postgres psql -U flink -d streaming
```
- Check streamed data in Postgres
```sql

       SELECT COUNT(*) FROM clickstream_events;
       SELECT * FROM clickstream_events ORDER BY event_timestamp DESC LIMIT 10;
```


## Project Structure

```
streaming-with-flink-spark/
â”œâ”€â”€ config/                      # Configuration files
â”‚   â”œâ”€â”€ flink-conf.yaml
â”‚   â””â”€â”€ spark-defaults.conf
â”œâ”€â”€ data/
â”‚   â””â”€â”€ schemas/                 # Avro schemas
â”‚       â”œâ”€â”€ clickstream-event.avsc
â”‚       â””â”€â”€ clickstream-event-readable.avsc
â”œâ”€â”€ doc/                         # Documentation & learning materials
â”‚   â”œâ”€â”€ windowing-syllabus.md           # Comprehensive windowing course
â”‚   â”œâ”€â”€ windowing-quick-reference.md    # Quick reference guide
â”‚   â””â”€â”€ quick_start.md
â”œâ”€â”€ docker-compose.yml           # Service definitions
â”œâ”€â”€ exercises/                   # Hands-on windowing exercises
â”‚   â”œâ”€â”€ README.md
â”‚   â”œâ”€â”€ flink/                   # Flink implementations
â”‚   â”‚   â””â”€â”€ solution/
â”‚   â”œâ”€â”€ spark/                   # Spark implementations
â”‚   â”‚   â””â”€â”€ solution/
â”‚   â””â”€â”€ sql/                     # Database schemas
â”œâ”€â”€ flink/                       # Flink jobs
â”‚   â”œâ”€â”€ pom.xml
â”‚   â””â”€â”€ src/
â”œâ”€â”€ kafka/                       # Data producer
â”‚   â”œâ”€â”€ produce-test-events.py  # Main producer script
â”‚   â””â”€â”€ README.md               # Producer documentation
â”œâ”€â”€ shared/
â”‚   â”œâ”€â”€ data-generator/         # Onboarding & utilities
â”‚   â”‚   â”œâ”€â”€ start-producer.sh
â”‚   â”‚   â”œâ”€â”€ README.md
â”‚   â”‚   â””â”€â”€ QUICK_REFERENCE.md
â”‚   â””â”€â”€ tests/
â””â”€â”€ spark/                      # Spark jobs
    â”œâ”€â”€ requirements.txt
    â””â”€â”€ src/
```

## Quick Start

- Getting started: [set up and generate mock data](doc/quick_start.md#quick-start)
- [Common commands](doc/quick_start.md#common-commands)
- [Common issues](doc/quick_start.md#common-issues)

## Learning Windowing Concepts

This repo includes a comprehensive learning path for stream processing windows:

**ðŸ“š Start Here**: [Windowing Syllabus](doc/windowing-syllabus.md)
- Complete course covering tumbling, sliding, and session windows
- Theory + hands-on exercises for both Flink and Spark
- Real-world patterns and best practices

**âš¡ Quick Reference**: [Windowing Cheat Sheet](doc/windowing-quick-reference.md)
- Code snippets for common patterns
- Performance tuning tips
- Debugging guide

**ðŸ’» Exercises**: [exercises/README.md](exercises/README.md)
- Starter code and complete solutions
- Session analytics deliverable (30-min gap-based windowing)
- Late data handling and watermark strategies

### Key Topics Covered
- **Window Types**: Tumbling, Sliding, Session
- **Watermark Strategies**: Late data handling, allowed lateness
- **Flink**: WindowAssigner, Trigger, Evictor, ProcessWindowFunction
- **Spark**: groupBy + window(), watermark(), custom session logic
- **Real-World Project**: E-commerce session analytics with gap-based windowing
