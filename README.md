# Streaming with Flink & Spark

A repo to explore different streaming mechanisms: Kafka, Flink, and Spark.
The main goal is to understand the core components of Flink and Spark in streaming pipelines and how each serves a different purpose.

## What to learn next

1. Start services âœ…
2. Generate test data âœ…
3. Build Flink streaming jobs (real-time processing)
4. Build Spark batch jobs (historical analysis)
5. Add monitoring (Prometheus/Grafana)

## How it works

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Producer   â”‚ â†’ Generates realistic clickstream events
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚    Kafka     â”‚ â†’ Message broker
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â”œâ”€â–º Flink  â†’ Real-time stream processing
       â”‚
       â””â”€â–º Spark  â†’ Batch processing & analytics
             â”‚
             â–¼
       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
       â”‚  MinIO   â”‚ â†’ Data lake storage
       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## Project Structure

```
streaming-with-flink-spark/
â”œâ”€â”€ config/                      # Configuration files
â”‚   â”œâ”€â”€ flink-conf.yaml
â”‚   â””â”€â”€ spark-defaults.conf
â”œâ”€â”€ data/
â”‚   â””â”€â”€ schemas/                 # Avro schemas
â”‚       â”œâ”€â”€ clickstream-event.avsc
â”‚       â””â”€â”€ clickstream-event-readable.avsc
â”œâ”€â”€ docker-compose.yml           # Service definitions
â”œâ”€â”€ flink/                       # Flink jobs
â”‚   â”œâ”€â”€ pom.xml
â”‚   â””â”€â”€ src/
â”œâ”€â”€ kafka/                       # Data producer
â”‚   â”œâ”€â”€ produce-test-events.py  # Main producer script
â”‚   â””â”€â”€ README.md               # Producer documentation
â”œâ”€â”€ shared/
â”‚   â”œâ”€â”€ data-generator/         # Onboarding & utilities
â”‚   â”‚   â”œâ”€â”€ start-producer.sh   # ğŸŒŸ New user script
â”‚   â”‚   â”œâ”€â”€ README.md
â”‚   â”‚   â””â”€â”€ QUICK_REFERENCE.md
â”‚   â””â”€â”€ tests/
â””â”€â”€ spark/                      # Spark jobs
    â”œâ”€â”€ requirements.txt
    â””â”€â”€ src/
```

## Quick Start

- Getting started: [set up and generate mock data](https://github.com/phamthiminhtu/streaming-with-flink-spark/blob/master/doc/quick_start.md#quick-start)
- [Common commands](https://github.com/phamthiminhtu/streaming-with-flink-spark/blob/master/doc/quick_start.md#common-commands)
- [Common issues](https://github.com/phamthiminhtu/streaming-with-flink-spark/blob/master/doc/quick_start.md#common-issues)
